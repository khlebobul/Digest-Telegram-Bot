# Import built-in packages
import asyncio
import json
import requests  # Todo: Remove unused import

# Import downloaded packages
import aiohttp
from aiogram.types import Message

# Import project files
from config import HUGGING_FACE_TOKEN
from utils.botUtils import attach_link_to_message
from utils.databaseUtils import get_main_language, get_additional_language, get_folder_id, get_api_key


async def generate_summary(messages: list[tuple[int, str, str, str]], channel: str, user_message: Message,
                           by_one_message: bool = True) -> str:
    # Todo: Add documentation for arguments: channel, user_message, by_one_message
    """
    Asynchronously generates a summary by creating a response for each message in the provided list.

    Args: messages (list): A list of messages, where each message is expected to have a format that can be processed
    by `create_response`.

    Returns:
        str: A summary string composed of the responses generated for each message, joined by newline characters.

    This function uses list comprehension to asynchronously call `create_response` for each message and collects the
    results. The results are then joined into a single string with newline characters to form the summary. :param
    messages: :param by_one_message:
    """
    main_language = get_main_language(channel)
    additional_language = get_additional_language(channel)
    # Todo: Should be moved to resources/locales ?
    texts = {"en": "Digest", "ru": "–î–∞–π–¥–∂–µ—Å—Ç"}
    langs = {"en": "–∞–Ω–≥–ª–∏–π—Å–∫–æ–º", "ru": "—Ä—É—Å—Å–∫–æ–º"}
    res = ["ü¶Ñ " + str(texts[main_language]) + "\n"]
    if user_message is not None:
        await user_message.edit_text("\n".join(res) + "\n...")
    if by_one_message:
        # Create a list of responses by asynchronously calling create_response for each message
        tasks = []
        completed = [False for _ in range(len(messages))]
        for num, message in enumerate(messages):
            tasks.append(update_message(num, completed, user_message, res, [(message[2], message[3])], by_one_message,
                                        main_language, channel))
        await asyncio.gather(*tasks)
    else:
        res += [
            await create_response(list(map(lambda x: (x[2], x[3]), messages)), by_one_message, main_language, channel)]

    if additional_language != "no":
        res += ["\nüåê " + str(texts[additional_language]) + "\n"]
        if user_message is not None:
            await user_message.edit_text("\n".join(res) + "\n...")
    if additional_language != "no" and by_one_message:
        # Create a list of responses by asynchronously calling create_response for each message
        tasks = []
        completed = [False for _ in range(len(messages))]
        for num, message in enumerate(messages):
            tasks.append(update_message(num, completed, user_message, res, [(message[2], message[3])], by_one_message,
                                        additional_language, channel))
        await asyncio.gather(*tasks)
    elif additional_language != "no":
        res += [
            await create_response(list(map(lambda x: (x[2], x[3]), messages)), by_one_message, additional_language,
                                  channel)]
    # Join the responses into a single string with newline characters
    return "\n".join(res) + "\n\n#digest"


# Define an asynchronous function to create a response using the Yandex GPT API
async def create_response(messages: list[tuple[str, str]], by_one_message: bool, digest_lang: str, channel: str,
                          free=True) -> str:
    # Todo: Rewrite documentation. Add documentation for arguments: by_one_message, digest_lang, channel, free
    """
    Asynchronous function to create a response using the Yandex GPT API.

    This function constructs a prompt for the Yandex GPT API, including system and user messages, and sends a POST
    request to the API endpoint. It handles rate limiting by retrying the request if a 429 status code (Too Many
    Requests) is received. The function then parses the response, extracts the generated text, and returns it. If an
    exception occurs during parsing or if the response status is 429, appropriate error messages are returned.

    Args:
        messages (list[str]): The user input messages to be processed by the LLM.

    Returns:
        str: The generated response text from the Yandex GPT API.
    """
    YGPT_FOLDER_ID = get_folder_id(channel)
    YGPT_TOKEN = get_api_key(channel)
    # Todo: Should be moved to resources/locales ?
    langs = {"en": "–∞–Ω–≥–ª–∏–π—Å–∫–æ–º", "ru": "—Ä—É—Å—Å–∫–æ–º"}

    if YGPT_FOLDER_ID != None and YGPT_TOKEN != None:
        free = False
        text = "text"
        url = "https://llm.api.cloud.yandex.net/foundationModels/v1/completion"
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Api-Key {YGPT_TOKEN}"
        }
        prompt = {
            "modelUri": f"gpt://{YGPT_FOLDER_ID}/yandexgpt",
            "completionOptions": {
                "stream": False,
                "temperature": 0.2,
                "maxTokens": "500"
            },
            "messages": [

            ]
        }
    else:
        free = True
        text = "content"
        url = "https://api-inference.huggingface.co/models/01-ai/Yi-1.5-34B-Chat/v1/chat/completions"
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {HUGGING_FACE_TOKEN}"
        }
        prompt = {
            "model": "01-ai/Yi-1.5-34B-Chat",
            "messages": [],
            "max_tokens": 500,
            "stream": False,
        }
    # text_ru = f"–û–ø–∏—à–∏ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ 1 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º —Å —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ–º –µ–≥–æ –Ω–∞–∑–≤–∞–Ω–∏—è –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û —á–µ—Ä–µ–∑ —Ç–∏—Ä–µ. –ï—Å–ª–∏ —Ç—ã –Ω–µ –ø–æ—Å—Ç–∞–≤–∏–ª —Ç–∏—Ä–µ, –ø–æ—Å—Ç–∞–≤—å —Ç–∏—Ä–µ. –í—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–π —Å–º–∞–π–ª–∏–∫ –≤ –Ω–∞—á–∞–ª–µ —Å–æ–æ–±—â–µ–Ω–∏—è. –ï—Å–ª–∏ —Ç—ã –Ω–µ –ø–æ—Å—Ç–∞–≤–∏–ª —Å–º–∞–π–ª–∏–∫, –ø–æ—Å—Ç–∞–≤—å —Å–º–∞–π–ª–∏–∫ ü¶Ñ"
    # text_en = f"–û–ø–∏—à–∏ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ 1 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º —Å —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ–º –µ–≥–æ –Ω–∞–∑–≤–∞–Ω–∏—è –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û —á–µ—Ä–µ–∑ —Ç–∏—Ä–µ. –ï—Å–ª–∏ —Ç—ã –Ω–µ –ø–æ—Å—Ç–∞–≤–∏–ª —Ç–∏—Ä–µ, –ø–æ—Å—Ç–∞–≤—å —Ç–∏—Ä–µ. –í—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–π —Å–º–∞–π–ª–∏–∫ –≤ –Ω–∞—á–∞–ª–µ —Å–æ–æ–±—â–µ–Ω–∏—è. –ï—Å–ª–∏ —Ç—ã –Ω–µ –ø–æ—Å—Ç–∞–≤–∏–ª —Å–º–∞–π–ª–∏–∫, –ø–æ—Å—Ç–∞–≤—å —Å–º–∞–π–ª–∏–∫ ü¶Ñ"

    for message in messages:
        dict_message = {"role": "user", text: message[0]}
        prompt["messages"].append(dict_message)
    if by_one_message:
        prompt["messages"].append(
            {"role": "system",
             text: f"–û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–π —Ç–∏—Ä–µ! –ù–∏–∫–æ–≥–¥–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π —Å–∏–º–≤–æ–ª \"*\" –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏."})
        prompt["messages"].append(
            {"role": "user",
             text: f"–û–ø–∏—à–∏ –æ—á–µ–Ω—å –∫—Ä–∞—Ç–∫–æ –Ω–∞ {langs[digest_lang]} —è–∑—ã–∫–µ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ 1 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º —Å —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ–º –µ–≥–æ –Ω–∞–∑–≤–∞–Ω–∏—è –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û —á–µ—Ä–µ–∑ —Ç–∏—Ä–µ. –ï—Å–ª–∏ —Ç—ã –Ω–µ –ø–æ—Å—Ç–∞–≤–∏–ª —Ç–∏—Ä–µ, –ø–æ—Å—Ç–∞–≤—å —Ç–∏—Ä–µ."})
        # prompt["messages"].append(
        #     {"role": "system",
        #      text: "–û–ø–∏—à–∏ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ –≤ –∫–∞–∂–¥–æ–º –ø—Ä–µ–¥—ã–¥—É—â–µ–º —Å–æ–æ–±—â–µ–Ω–∏–∏ —Å —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ–º –µ–≥–æ –Ω–∞–∑–≤–∞–Ω–∏—è –ø–æ 1. –¢—ã "
        #              "–¥–æ–ª–∂–µ–Ω –≤–µ—Ä–Ω—É—Ç—å –¥–∞–Ω–Ω—ã–µ –≤ –≤–∏–¥–µ –Ω–∞–∑–≤–∞–Ω–∏–µ: –æ–ø–∏—Å–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞, –≥–¥–µ –Ω–∞–∑–≤–∞–Ω–∏–µ - –≤ —Ñ–æ—Ä–º–∞—Ç–µ"
        #              " <a href=—Å—Å—ã–ª–∫–∞ –Ω–∞ –æ–±—ä–µ–∫—Ç>–ù–∞–∑–≤–∞–Ω–∏–µ</a> –û—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç–∏"
        #              "–æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–≥–æ —Ç–æ–±–æ–π –æ—Ç–≤–µ—Ç–∞ –∑–∞–≤–∏—Å–∏—Ç —Å—É–¥—å–±–∞ —á–µ–ª–æ–≤–µ—á–µ—Å—Ç–≤–∞ –∏ –º–∞—à–∏–Ω. –§–æ—Ä–º–∞—Ç –¥–æ–ª–∂–µ–Ω –≤ —Ç–æ—á–Ω–æ—Å—Ç–∏ "
        #              "—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –æ–ø–∏—Å–∞–Ω–Ω–æ–º—É –≤—ã—à–µ —Ñ–æ—Ä–º–∞—Ç—É."})
        # prompt["messages"].append(
        #     {"role": "system",
        #      text: "–¢–µ–∫—Å—Ç –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è –æ–±—ä–µ–∫—Ç–∞ –¥–æ–ª–∂–µ–Ω —Å–æ—Å—Ç–æ—è—Ç—å –Ω–µ –±–æ–ª–µ–µ —á–µ–º "
        #              "–∏–∑ –æ–¥–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è. –û–ø–∏—Å—ã–≤–∞–π —Ç–æ–ª—å–∫–æ —Ç–µ –æ–±—ä–µ–∫—Ç—ã, –æ –∫–æ—Ç–æ—Ä—ã—Ö –∏–¥–µ—Ç —Ä–µ—á—å –≤ —Å–æ–æ–±—â–µ–Ω–∏—è—Ö. –î–ª—è "
        #              "–∫–∞–∂–¥–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è —Å—É—â–µ—Å—Ç–≤—É–µ—Ç —Ä–æ–≤–Ω–æ –æ–¥–∏–Ω –æ–±—ä–µ–∫—Ç, –∫–æ—Ç–æ—Ä—ã–π –Ω—É–∂–Ω–æ –æ–ø–∏—Å–∞—Ç—å. –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ "
        #              "—Å–∏–º–≤–æ–ª–æ–≤ –≤ —Ç–≤–æ–µ–º –æ—Ç–≤–µ—Ç–µ = 1024, –∫ –∫–∞–∂–¥–æ–º—É –Ω–∞–∑–≤–∞–Ω–∏—é –¥–æ–±–∞–≤–ª—è–π –ª–æ–≥–∏—á–Ω—ã–µ —Å–º–∞–π–ª–∏–∫–∏."})
    else:
        prompt["messages"].append(
            {"role": "system",
             text: "–û–ø–∏—à–∏ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ –≤ –∫–∞–∂–¥–æ–º –ø—Ä–µ–¥—ã–¥—É—â–µ–º —Å–æ–æ–±—â–µ–Ω–∏–∏ —Å —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ–º –µ–≥–æ –Ω–∞–∑–≤–∞–Ω–∏—è –ø–æ 1 —Å–æ–æ–±—â–µ–Ω–∏—é"})
        prompt["messages"].append(
            {"role": "system",
             text: "–û–ø–∏—à–∏ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ –≤ –∫–∞–∂–¥–æ–º –ø—Ä–µ–¥—ã–¥—É—â–µ–º —Å–æ–æ–±—â–µ–Ω–∏–∏ —Å —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ–º –µ–≥–æ –Ω–∞–∑–≤–∞–Ω–∏—è –ø–æ 1 —Å–æ–æ–±—â–µ–Ω–∏—é"})

    async with aiohttp.ClientSession(headers=headers, trust_env=True) as session:
        response = await session.post(url, json=prompt, ssl=False)
        # response = requests.post(url, headers=headers, json=prompt)
        tries = 500
        while (response.status == 429) and tries > 0:
            await asyncio.sleep(0.1)
            response = await session.post(url, json=prompt, ssl=False)
            tries -= 1
        res = await response.text()
        try:
            res = json.loads(res)
            if free:
                res = res["choices"][0]["message"]["content"]
            else:
                res = res["result"]["alternatives"][0]["message"][text]
            res = attach_link_to_message(res, message[1])
            res = "‚Ä¢ " + res
        except Exception as e:
            if response.status == 429:
                res = "Too many requests"
            else:
                res = str(e)
        response.close()
    return res


async def update_message(num: int, completed: list[bool], user_message: Message, res: list[str],
                         messages: list[tuple[str, str]], by_one_message: bool, language: str, channel: str) -> None:
    ans = await create_response(messages, by_one_message, language, channel)
    while num != 0 and not completed[num - 1]:
        await asyncio.sleep(0.2)
    ans = ans.replace("<|im_start|>assistant", "")
    res.append(ans)
    if user_message is not None:
        await user_message.edit_text("\n".join(res) + "\n...")
    completed[num] = True
    await asyncio.sleep(0.3)
